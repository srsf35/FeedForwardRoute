{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6820c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfe566",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d33f384d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_cleveland.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "820d8ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "  ca thal  \n",
       "0  0    6  \n",
       "1  3    3  \n",
       "2  2    7  \n",
       "3  0    3  \n",
       "4  0    3  "
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.get_dummies(df.drop(['num'], axis = 1), columns=['ca', 'thal', 'cp', 'slope', 'restecg'])\n",
    "y = df['num'].apply(lambda x: 1 if x>0 else 0)\n",
    "df.drop(['num'], axis = 1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "6c4ecae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "129c0320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>ca_0</th>\n",
       "      <th>ca_1</th>\n",
       "      <th>...</th>\n",
       "      <th>cp_1</th>\n",
       "      <th>cp_2</th>\n",
       "      <th>cp_3</th>\n",
       "      <th>cp_4</th>\n",
       "      <th>slope_1</th>\n",
       "      <th>slope_2</th>\n",
       "      <th>slope_3</th>\n",
       "      <th>restecg_0</th>\n",
       "      <th>restecg_1</th>\n",
       "      <th>restecg_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>206</td>\n",
       "      <td>0</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>118</td>\n",
       "      <td>242</td>\n",
       "      <td>0</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>139</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>231</td>\n",
       "      <td>0</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  trestbps  chol  fbs  thalach  exang  oldpeak  ca_0  ca_1  ...  \\\n",
       "24    60    1       130   206    0      132      1      2.4     0     0  ...   \n",
       "260   44    0       118   242    0      149      0      0.3     0     1  ...   \n",
       "236   56    1       130   283    1      103      1      1.6     1     0  ...   \n",
       "104   49    1       120   188    0      139      0      2.0     0     0  ...   \n",
       "211   38    1       120   231    0      182      1      3.8     1     0  ...   \n",
       "\n",
       "     cp_1  cp_2  cp_3  cp_4  slope_1  slope_2  slope_3  restecg_0  restecg_1  \\\n",
       "24      0     0     0     1        0        1        0          0          0   \n",
       "260     0     0     1     0        0        1        0          1          0   \n",
       "236     0     0     0     1        0        0        1          0          0   \n",
       "104     0     0     1     0        0        1        0          1          0   \n",
       "211     1     0     0     0        0        1        0          1          0   \n",
       "\n",
       "     restecg_2  \n",
       "24           1  \n",
       "260          0  \n",
       "236          1  \n",
       "104          0  \n",
       "211          0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "21f7a392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24     1\n",
       "260    0\n",
       "236    1\n",
       "104    1\n",
       "211    1\n",
       "Name: num, dtype: int64"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d98ddc",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "1b2847e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b899e7",
   "metadata": {},
   "source": [
    "# Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "9f5964b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=8, activation='relu', input_dim=len(x_train.columns)))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=8, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "bb41c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1248cb09",
   "metadata": {},
   "source": [
    "# Fit, Predict, and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "f610c8cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 0s 79ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.6945 - val_accuracy: 0.4667\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6927 - accuracy: 0.5165 - val_loss: 0.6946 - val_accuracy: 0.4667\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6927 - accuracy: 0.5220 - val_loss: 0.6947 - val_accuracy: 0.4667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srs68\\anaconda3\\envs\\tensforflow\\lib\\site-packages\\keras\\engine\\data_adapter.py:1508: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6927 - accuracy: 0.5220 - val_loss: 0.6950 - val_accuracy: 0.4333\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6926 - accuracy: 0.5220 - val_loss: 0.6953 - val_accuracy: 0.4333\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6926 - accuracy: 0.5220 - val_loss: 0.6954 - val_accuracy: 0.4333\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6925 - accuracy: 0.5220 - val_loss: 0.6956 - val_accuracy: 0.4333\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6926 - accuracy: 0.5220 - val_loss: 0.6960 - val_accuracy: 0.4000\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6925 - accuracy: 0.5220 - val_loss: 0.6965 - val_accuracy: 0.4000\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6923 - accuracy: 0.5220 - val_loss: 0.6971 - val_accuracy: 0.4000\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6921 - accuracy: 0.5275 - val_loss: 0.6983 - val_accuracy: 0.4000\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6915 - accuracy: 0.5495 - val_loss: 0.6989 - val_accuracy: 0.4000\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6914 - accuracy: 0.5440 - val_loss: 0.6990 - val_accuracy: 0.4000\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6913 - accuracy: 0.5385 - val_loss: 0.6990 - val_accuracy: 0.4333\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6912 - accuracy: 0.5440 - val_loss: 0.6991 - val_accuracy: 0.4000\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6911 - accuracy: 0.5604 - val_loss: 0.6992 - val_accuracy: 0.4000\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6911 - accuracy: 0.5440 - val_loss: 0.6992 - val_accuracy: 0.4333\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6917 - accuracy: 0.5440 - val_loss: 0.6992 - val_accuracy: 0.4333\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6911 - accuracy: 0.5440 - val_loss: 0.6993 - val_accuracy: 0.4667\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6914 - accuracy: 0.5165 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6993 - val_accuracy: 0.4333\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6906 - accuracy: 0.5604 - val_loss: 0.6994 - val_accuracy: 0.5000\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6905 - accuracy: 0.5440 - val_loss: 0.6994 - val_accuracy: 0.4333\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6904 - accuracy: 0.5659 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6908 - accuracy: 0.5385 - val_loss: 0.6995 - val_accuracy: 0.5000\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6914 - accuracy: 0.5385 - val_loss: 0.6994 - val_accuracy: 0.4333\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6901 - accuracy: 0.5495 - val_loss: 0.6996 - val_accuracy: 0.5000\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 38ms/step - loss: 0.6900 - accuracy: 0.5549 - val_loss: 0.6998 - val_accuracy: 0.4333\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6899 - accuracy: 0.5769 - val_loss: 0.6997 - val_accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6902 - accuracy: 0.5440 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6906 - accuracy: 0.5440 - val_loss: 0.6999 - val_accuracy: 0.4333\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6897 - accuracy: 0.5714 - val_loss: 0.6998 - val_accuracy: 0.5000\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6898 - accuracy: 0.5659 - val_loss: 0.7000 - val_accuracy: 0.5000\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6895 - accuracy: 0.5714 - val_loss: 0.6999 - val_accuracy: 0.5000\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6895 - accuracy: 0.5659 - val_loss: 0.7001 - val_accuracy: 0.4667\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6900 - accuracy: 0.5659 - val_loss: 0.7001 - val_accuracy: 0.5000\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6907 - accuracy: 0.5385 - val_loss: 0.7001 - val_accuracy: 0.4667\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6908 - accuracy: 0.5604 - val_loss: 0.7001 - val_accuracy: 0.4667\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6894 - accuracy: 0.5604 - val_loss: 0.7003 - val_accuracy: 0.4667\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6891 - accuracy: 0.5769 - val_loss: 0.7000 - val_accuracy: 0.4667\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6888 - accuracy: 0.5714 - val_loss: 0.6993 - val_accuracy: 0.5000\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6888 - accuracy: 0.5769 - val_loss: 0.7005 - val_accuracy: 0.4667\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6889 - accuracy: 0.5714 - val_loss: 0.7005 - val_accuracy: 0.5333\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6893 - accuracy: 0.5934 - val_loss: 0.7007 - val_accuracy: 0.4667\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6887 - accuracy: 0.5659 - val_loss: 0.7006 - val_accuracy: 0.5000\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6899 - accuracy: 0.5824 - val_loss: 0.7008 - val_accuracy: 0.4667\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6889 - accuracy: 0.5549 - val_loss: 0.7007 - val_accuracy: 0.5333\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6905 - accuracy: 0.5769 - val_loss: 0.7009 - val_accuracy: 0.4667\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6883 - accuracy: 0.5824 - val_loss: 0.7005 - val_accuracy: 0.5333\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6876 - accuracy: 0.5714 - val_loss: 0.7006 - val_accuracy: 0.5333\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6887 - accuracy: 0.5659 - val_loss: 0.7013 - val_accuracy: 0.4333\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6883 - accuracy: 0.5879 - val_loss: 0.7003 - val_accuracy: 0.5000\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6877 - accuracy: 0.5989 - val_loss: 0.6993 - val_accuracy: 0.5667\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6874 - accuracy: 0.5714 - val_loss: 0.7013 - val_accuracy: 0.4667\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6873 - accuracy: 0.5824 - val_loss: 0.7004 - val_accuracy: 0.5333\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6878 - accuracy: 0.5604 - val_loss: 0.7007 - val_accuracy: 0.5333\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6864 - accuracy: 0.5934 - val_loss: 0.7012 - val_accuracy: 0.4667\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6870 - accuracy: 0.5659 - val_loss: 0.7013 - val_accuracy: 0.4667\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6862 - accuracy: 0.5824 - val_loss: 0.7006 - val_accuracy: 0.5333\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6864 - accuracy: 0.5879 - val_loss: 0.7010 - val_accuracy: 0.5667\n",
      "Epoch 62/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6857 - accuracy: 0.5824 - val_loss: 0.7012 - val_accuracy: 0.5333\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6855 - accuracy: 0.5824 - val_loss: 0.7013 - val_accuracy: 0.5333\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6857 - accuracy: 0.5879 - val_loss: 0.7013 - val_accuracy: 0.5667\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6859 - accuracy: 0.5659 - val_loss: 0.7022 - val_accuracy: 0.4667\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6851 - accuracy: 0.6099 - val_loss: 0.7018 - val_accuracy: 0.5667\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6849 - accuracy: 0.5769 - val_loss: 0.7022 - val_accuracy: 0.5667\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6842 - accuracy: 0.5879 - val_loss: 0.7023 - val_accuracy: 0.5333\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6874 - accuracy: 0.5659 - val_loss: 0.7025 - val_accuracy: 0.5667\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6837 - accuracy: 0.5769 - val_loss: 0.7026 - val_accuracy: 0.5667\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6835 - accuracy: 0.5989 - val_loss: 0.7027 - val_accuracy: 0.5667\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6833 - accuracy: 0.5934 - val_loss: 0.7027 - val_accuracy: 0.5667\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6830 - accuracy: 0.6044 - val_loss: 0.7032 - val_accuracy: 0.5333\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6844 - accuracy: 0.5714 - val_loss: 0.7030 - val_accuracy: 0.5667\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.6154 - val_loss: 0.7036 - val_accuracy: 0.5667\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6822 - accuracy: 0.5879 - val_loss: 0.7036 - val_accuracy: 0.5333\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6821 - accuracy: 0.5989 - val_loss: 0.7042 - val_accuracy: 0.5667\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6821 - accuracy: 0.5714 - val_loss: 0.7039 - val_accuracy: 0.5333\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6826 - accuracy: 0.5989 - val_loss: 0.7049 - val_accuracy: 0.5667\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6818 - accuracy: 0.5440 - val_loss: 0.7051 - val_accuracy: 0.5667\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6814 - accuracy: 0.5769 - val_loss: 0.7047 - val_accuracy: 0.5333\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6830 - accuracy: 0.5934 - val_loss: 0.7067 - val_accuracy: 0.5667\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6799 - accuracy: 0.5769 - val_loss: 0.7050 - val_accuracy: 0.5667\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6791 - accuracy: 0.6044 - val_loss: 0.7052 - val_accuracy: 0.5667\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 26ms/step - loss: 0.6785 - accuracy: 0.5989 - val_loss: 0.7056 - val_accuracy: 0.5667\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6781 - accuracy: 0.6044 - val_loss: 0.7061 - val_accuracy: 0.5667\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6799 - accuracy: 0.5879 - val_loss: 0.7062 - val_accuracy: 0.5333\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6788 - accuracy: 0.5934 - val_loss: 0.7061 - val_accuracy: 0.5667\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6775 - accuracy: 0.6264 - val_loss: 0.7064 - val_accuracy: 0.5333\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6765 - accuracy: 0.6264 - val_loss: 0.7076 - val_accuracy: 0.5667\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6780 - accuracy: 0.6264 - val_loss: 0.7125 - val_accuracy: 0.5000\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6766 - accuracy: 0.5879 - val_loss: 0.7072 - val_accuracy: 0.5333\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6765 - accuracy: 0.5934 - val_loss: 0.7078 - val_accuracy: 0.5000\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6853 - accuracy: 0.5659 - val_loss: 0.7040 - val_accuracy: 0.4667\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6817 - accuracy: 0.6154 - val_loss: 0.7077 - val_accuracy: 0.5667\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6762 - accuracy: 0.6374 - val_loss: 0.7150 - val_accuracy: 0.5000\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6740 - accuracy: 0.5879 - val_loss: 0.7085 - val_accuracy: 0.5000\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6749 - accuracy: 0.6099 - val_loss: 0.7085 - val_accuracy: 0.5667\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6803 - accuracy: 0.6044 - val_loss: 0.7059 - val_accuracy: 0.4667\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6792 - accuracy: 0.5934 - val_loss: 0.7089 - val_accuracy: 0.5667\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6728 - accuracy: 0.6429 - val_loss: 0.7180 - val_accuracy: 0.4667\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6835 - accuracy: 0.5659 - val_loss: 0.6973 - val_accuracy: 0.4333\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6894 - accuracy: 0.5440 - val_loss: 0.7041 - val_accuracy: 0.4667\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6788 - accuracy: 0.6044 - val_loss: 0.7092 - val_accuracy: 0.5667\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6716 - accuracy: 0.6484 - val_loss: 0.7168 - val_accuracy: 0.5333\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6722 - accuracy: 0.5934 - val_loss: 0.7079 - val_accuracy: 0.4667\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6743 - accuracy: 0.6209 - val_loss: 0.7132 - val_accuracy: 0.5333\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6726 - accuracy: 0.6264 - val_loss: 0.7212 - val_accuracy: 0.5000\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6689 - accuracy: 0.6154 - val_loss: 0.7086 - val_accuracy: 0.4667\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6737 - accuracy: 0.6264 - val_loss: 0.7108 - val_accuracy: 0.5333\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6678 - accuracy: 0.6429 - val_loss: 0.7244 - val_accuracy: 0.4667\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6733 - accuracy: 0.6099 - val_loss: 0.7148 - val_accuracy: 0.5667\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6662 - accuracy: 0.6374 - val_loss: 0.7135 - val_accuracy: 0.5667\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6662 - accuracy: 0.6154 - val_loss: 0.7138 - val_accuracy: 0.5667\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6670 - accuracy: 0.6154 - val_loss: 0.7087 - val_accuracy: 0.4333\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6674 - accuracy: 0.6593 - val_loss: 0.7198 - val_accuracy: 0.5333\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6633 - accuracy: 0.6099 - val_loss: 0.7077 - val_accuracy: 0.4333\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6725 - accuracy: 0.6099 - val_loss: 0.7121 - val_accuracy: 0.4333\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6613 - accuracy: 0.6758 - val_loss: 0.7216 - val_accuracy: 0.6000\n",
      "Epoch 120/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6606 - accuracy: 0.6264 - val_loss: 0.7152 - val_accuracy: 0.6000\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6602 - accuracy: 0.6593 - val_loss: 0.7430 - val_accuracy: 0.5333\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6882 - accuracy: 0.5604 - val_loss: 0.7151 - val_accuracy: 0.5000\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6586 - accuracy: 0.6593 - val_loss: 0.7161 - val_accuracy: 0.5333\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6560 - accuracy: 0.6758 - val_loss: 0.7179 - val_accuracy: 0.6000\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6636 - accuracy: 0.6538 - val_loss: 0.7266 - val_accuracy: 0.5667\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6624 - accuracy: 0.6484 - val_loss: 0.7254 - val_accuracy: 0.6000\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6642 - accuracy: 0.6758 - val_loss: 0.7289 - val_accuracy: 0.5667\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6533 - accuracy: 0.6538 - val_loss: 0.7183 - val_accuracy: 0.5333\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6547 - accuracy: 0.6813 - val_loss: 0.7169 - val_accuracy: 0.4000\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6604 - accuracy: 0.6209 - val_loss: 0.7075 - val_accuracy: 0.4667\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6583 - accuracy: 0.6703 - val_loss: 0.7208 - val_accuracy: 0.5333\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6514 - accuracy: 0.6758 - val_loss: 0.7443 - val_accuracy: 0.6333\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 40ms/step - loss: 0.6582 - accuracy: 0.6374 - val_loss: 0.7260 - val_accuracy: 0.5667\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 39ms/step - loss: 0.6482 - accuracy: 0.6758 - val_loss: 0.7288 - val_accuracy: 0.5667\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6557 - accuracy: 0.6538 - val_loss: 0.6958 - val_accuracy: 0.5000\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6665 - accuracy: 0.6209 - val_loss: 0.7219 - val_accuracy: 0.4333\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6521 - accuracy: 0.6538 - val_loss: 0.7223 - val_accuracy: 0.4333\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6491 - accuracy: 0.6703 - val_loss: 0.7245 - val_accuracy: 0.5667\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6505 - accuracy: 0.6538 - val_loss: 0.7163 - val_accuracy: 0.4000\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6464 - accuracy: 0.7088 - val_loss: 0.7428 - val_accuracy: 0.6000\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6526 - accuracy: 0.6209 - val_loss: 0.7317 - val_accuracy: 0.5667\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6435 - accuracy: 0.6868 - val_loss: 0.7319 - val_accuracy: 0.5667\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6426 - accuracy: 0.6923 - val_loss: 0.7340 - val_accuracy: 0.5667\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6448 - accuracy: 0.6923 - val_loss: 0.7208 - val_accuracy: 0.4000\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6468 - accuracy: 0.6813 - val_loss: 0.7249 - val_accuracy: 0.4333\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6462 - accuracy: 0.6538 - val_loss: 0.7280 - val_accuracy: 0.4667\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6422 - accuracy: 0.6813 - val_loss: 0.7469 - val_accuracy: 0.5667\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6718 - accuracy: 0.6044 - val_loss: 0.7247 - val_accuracy: 0.4333\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6473 - accuracy: 0.6813 - val_loss: 0.7697 - val_accuracy: 0.6333\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6500 - accuracy: 0.6429 - val_loss: 0.7301 - val_accuracy: 0.5000\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6405 - accuracy: 0.6813 - val_loss: 0.7436 - val_accuracy: 0.5667\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6524 - accuracy: 0.6538 - val_loss: 0.7518 - val_accuracy: 0.6333\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6407 - accuracy: 0.6758 - val_loss: 0.7478 - val_accuracy: 0.5667\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6366 - accuracy: 0.6703 - val_loss: 0.7219 - val_accuracy: 0.4000\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6401 - accuracy: 0.6593 - val_loss: 0.7471 - val_accuracy: 0.6000\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6366 - accuracy: 0.6923 - val_loss: 0.7424 - val_accuracy: 0.5667\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6383 - accuracy: 0.6868 - val_loss: 0.7682 - val_accuracy: 0.6667\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6698 - accuracy: 0.5769 - val_loss: 0.7126 - val_accuracy: 0.4000\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6393 - accuracy: 0.6923 - val_loss: 0.7645 - val_accuracy: 0.6667\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6399 - accuracy: 0.6484 - val_loss: 0.7334 - val_accuracy: 0.4667\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6369 - accuracy: 0.6978 - val_loss: 0.7332 - val_accuracy: 0.4667\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6331 - accuracy: 0.6923 - val_loss: 0.7591 - val_accuracy: 0.6667\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6472 - accuracy: 0.6923 - val_loss: 0.6812 - val_accuracy: 0.5333\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6789 - accuracy: 0.5769 - val_loss: 0.7004 - val_accuracy: 0.4333\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6606 - accuracy: 0.6703 - val_loss: 0.7283 - val_accuracy: 0.4000\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6421 - accuracy: 0.6703 - val_loss: 0.7271 - val_accuracy: 0.4000\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6364 - accuracy: 0.7088 - val_loss: 0.7471 - val_accuracy: 0.5667\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 34ms/step - loss: 0.6317 - accuracy: 0.6813 - val_loss: 0.7438 - val_accuracy: 0.5667\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6346 - accuracy: 0.6703 - val_loss: 0.7304 - val_accuracy: 0.4333\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 35ms/step - loss: 0.6361 - accuracy: 0.6923 - val_loss: 0.7764 - val_accuracy: 0.6667\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 36ms/step - loss: 0.6396 - accuracy: 0.6813 - val_loss: 0.7445 - val_accuracy: 0.5667\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 0.6315 - accuracy: 0.6813 - val_loss: 0.7433 - val_accuracy: 0.5333\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 32ms/step - loss: 0.6532 - accuracy: 0.6374 - val_loss: 0.7601 - val_accuracy: 0.6333\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6302 - accuracy: 0.6868 - val_loss: 0.7474 - val_accuracy: 0.5333\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6355 - accuracy: 0.6978 - val_loss: 0.7207 - val_accuracy: 0.4000\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 31ms/step - loss: 0.6349 - accuracy: 0.6648 - val_loss: 0.7462 - val_accuracy: 0.5667\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6285 - accuracy: 0.6978 - val_loss: 0.7538 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 37ms/step - loss: 0.6328 - accuracy: 0.6978 - val_loss: 0.7732 - val_accuracy: 0.6667\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6365 - accuracy: 0.6429 - val_loss: 0.7377 - val_accuracy: 0.5000\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6282 - accuracy: 0.7088 - val_loss: 0.7644 - val_accuracy: 0.6667\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6704 - accuracy: 0.6593 - val_loss: 0.6887 - val_accuracy: 0.5000\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6861 - accuracy: 0.5549 - val_loss: 0.6780 - val_accuracy: 0.5333\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6727 - accuracy: 0.5879 - val_loss: 0.7016 - val_accuracy: 0.4333\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6406 - accuracy: 0.6758 - val_loss: 0.7560 - val_accuracy: 0.6667\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6318 - accuracy: 0.7088 - val_loss: 0.7728 - val_accuracy: 0.6667\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6348 - accuracy: 0.6648 - val_loss: 0.7417 - val_accuracy: 0.5000\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6299 - accuracy: 0.7033 - val_loss: 0.7947 - val_accuracy: 0.6667\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6252 - accuracy: 0.6813 - val_loss: 0.7320 - val_accuracy: 0.4000\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 30ms/step - loss: 0.6264 - accuracy: 0.7033 - val_loss: 0.7587 - val_accuracy: 0.6333\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6268 - accuracy: 0.6978 - val_loss: 0.7499 - val_accuracy: 0.6000\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6307 - accuracy: 0.6978 - val_loss: 0.7721 - val_accuracy: 0.6667\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6439 - accuracy: 0.6813 - val_loss: 0.7604 - val_accuracy: 0.6333\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6391 - accuracy: 0.6813 - val_loss: 0.6820 - val_accuracy: 0.4667\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6588 - accuracy: 0.6264 - val_loss: 0.7391 - val_accuracy: 0.5000\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6404 - accuracy: 0.6978 - val_loss: 0.7255 - val_accuracy: 0.4333\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6261 - accuracy: 0.7253 - val_loss: 0.7744 - val_accuracy: 0.6667\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6389 - accuracy: 0.7363 - val_loss: 0.7917 - val_accuracy: 0.6667\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 29ms/step - loss: 0.6359 - accuracy: 0.6703 - val_loss: 0.7653 - val_accuracy: 0.6667\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 27ms/step - loss: 0.6223 - accuracy: 0.6978 - val_loss: 0.7398 - val_accuracy: 0.5000\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 28ms/step - loss: 0.6237 - accuracy: 0.7143 - val_loss: 0.7663 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a1e7e86d0>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=200, validation_split=0.14, batch_size =100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a5cc71",
   "metadata": {},
   "source": [
    "### Test Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "60525b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step - loss: 0.7170 - accuracy: 0.6044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7170279622077942, 0.6043956279754639]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "adce4302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6043956043956044"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model.predict(x_test)\n",
    "y_hat = [0 if val < 0.5 else 1 for val in y_hat]\n",
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3da41a",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "86b84102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tfmodel\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('tfmodel')\n",
    "del model\n",
    "model = load_model('tfmodel')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
